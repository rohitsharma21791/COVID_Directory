{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Covid_model2_MobileNet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1sBbDdKfB7xQxS4mLRpyMwVnTse_JkJCm",
      "authorship_tag": "ABX9TyPcjogdz9sceU9riv24UMog",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitsharma21791/COVID_Directory/blob/main/Covid_model2_MobileNetv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAAtJjn5ZYVk"
      },
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG0PfnY9idWI"
      },
      "source": [
        "%reset -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ghZnATJiv9v"
      },
      "source": [
        "!unrar x -Y \"/content/drive/MyDrive/Gray.rar\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDn0t0i1iwiP"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
        "from keras.callbacks import EarlyStopping,CSVLogger\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWE68qbIjSmw"
      },
      "source": [
        "##### Import Python Files for Confusion_matrix and Precision and Recall Caluclation\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from distutils.file_util import copy_file\n",
        "copy_file(\"/content/drive/MyDrive/Colab Notebooks/make_confusion_matrix.py\", \"/content/\")\n",
        "copy_file(\"/content/drive/MyDrive/Colab Notebooks/calc_precision_recall.py\", \"/content/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X89_5LRBjVn1"
      },
      "source": [
        "dir = '/content/Covid_MI'\n",
        "if os.path.exists(dir):\n",
        "    shutil.rmtree(dir)\n",
        "src_dir1='/content/Gray/ECG_covid'\n",
        " \n",
        "dst_dir1 ='/content/Covid_MI'\n",
        "  \n",
        "shutil.copytree( src_dir1, dst_dir1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezi12InrkXvY"
      },
      "source": [
        "################## Read the Images and Labels##########################\n",
        "\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "image_directory = '/content/Covid_MI/'\n",
        "SIZE =112\n",
        "dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
        "label = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.\n",
        "\n",
        "Covid_images = os.listdir(image_directory + 'ECG Images of COVID-19 Patients (250)/')\n",
        "for i, image_name in enumerate(Covid_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
        "    \n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = cv2.imread((image_directory + 'ECG Images of COVID-19 Patients (250)/' + image_name),0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        dataset.append(np.array(image))\n",
        "        label.append(1)\n",
        "\n",
        "#Iterate through all images in Uninfected folder, resize to 64 x 64\n",
        "#Then save into the same numpy array 'dataset' but with label 1\n",
        "\n",
        "MI_images = os.listdir(image_directory + 'ECG Images of Patient that have abnormal heart beats (548)/')\n",
        "for i, image_name in enumerate(MI_images):\n",
        "    if (image_name.split('.')[1] == 'jpg'):\n",
        "        image = cv2.imread((image_directory +  'ECG Images of Patient that have abnormal heart beats (548)/' + image_name),0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        dataset.append(np.array(image))\n",
        "        label.append(0)\n",
        "\n",
        "       \n",
        "\n",
        "dataset = np.array(dataset)\n",
        "label = np.array(label)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRL80X7ELxQ7"
      },
      "source": [
        "########################## Split train, test and valid ############################\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "X_train1, X_test, y_train1, y_test = train_test_split(dataset,label, test_size = 0.1,random_state = 32,shuffle=True,stratify=label)\n",
        "X_train, X_val, y_train, y_val=train_test_split(X_train1,y_train1, test_size = 0.1, random_state = 32,shuffle=True,stratify=y_train1)\n",
        "print(X_train.shape)\n",
        "print(y_train1.shape)\n",
        "\n",
        "y_test_label=y_test\n",
        "#y_test=to_categorical(y_test)\n",
        "#y_train=to_categorical(y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3kl9pEgM9D8"
      },
      "source": [
        "\n",
        "######## Expand dimension to match with output of the model############\n",
        "y_train=tf.expand_dims(input=y_train, axis=1)\n",
        "y_train=tf.expand_dims(input=y_train, axis=1)\n",
        "y_test=tf.expand_dims(input=y_test, axis=1)\n",
        "y_test=tf.expand_dims(input=y_test, axis=1)\n",
        "\n",
        "y_val=tf.expand_dims(input=y_val, axis=1)\n",
        "y_val=tf.expand_dims(input=y_val, axis=1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        " rotation_range=0,\n",
        " width_shift_range=3,\n",
        " height_shift_range=3,\n",
        " horizontal_flip=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkZ8Dt69kbie"
      },
      "source": [
        "\n",
        "#Without scaling (normalize) the training may not converge. \n",
        "#Normalization is a rescaling of the data from the original range \n",
        "#so that all values are within the range of 0 and 1.\n",
        "\n",
        "X_train=np.array(X_train).reshape(-1,SIZE, SIZE,1)\n",
        "X_train=X_train/255.0\n",
        "y_train=np.array(y_train).reshape(-1,1)\n",
        "y_train=tf.expand_dims(input=y_train, axis=1)\n",
        "y_train=tf.expand_dims(input=y_train, axis=1)\n",
        "\n",
        "\n",
        "X_val=np.array(X_val).reshape(-1,SIZE, SIZE,1)\n",
        "X_val=X_val/255.0\n",
        "y_val=np.array(y_val).reshape(-1,1)\n",
        "y_val=tf.expand_dims(input=y_val, axis=1)\n",
        "y_val=tf.expand_dims(input=y_val, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_test=np.array(X_test).reshape(-1,SIZE, SIZE,1)\n",
        "X_test=X_test/255.0\n",
        "y_test=np.array(y_test).reshape(-1,1)\n",
        "\n",
        "\n",
        "\n",
        "y_test=tf.expand_dims(input=y_test, axis=1)\n",
        "y_test=tf.expand_dims(input=y_test, axis=1)\n",
        "train_it= datagen.flow(X_train, y_train, batch_size = 32)\n",
        "Val_it=datagen.flow(X_val, y_val,batch_size=32)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADUZUav7keGv"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Aug  7 23:33:36 2021\n",
        "\n",
        "@author: Sharma\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU, add\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from time import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "def h_sigmoid(x):\n",
        "    return tf.nn.relu6(x + 3) / 6\n",
        "\n",
        "def h_swish(x):\n",
        "    return x * h_sigmoid(x)\n",
        "\n",
        "def mobile_netv3(input_shape,n_classes):\n",
        "    \n",
        "    def se_block(x1,input_channels,r=16):\n",
        "        x=GlobalAvgPool2D()(x1)\n",
        "        x=Dense(units=input_channels//r)(x)\n",
        "        x=ReLU()(x)\n",
        "        x=Dense(units=input_channels)(x)\n",
        "        x=h_sigmoid(x)\n",
        "        x=tf.expand_dims(input=x, axis=1)\n",
        "        x=tf.expand_dims(input=x, axis=1)\n",
        "        \n",
        "        x=x1*x\n",
        "        return x\n",
        "    \n",
        "    def BottleNeck(x1,in_size,exp_size,out_size,s,is_se_existing,NL,k):\n",
        "        x=Conv2D(filters=exp_size,kernel_size=(1, 1),strides=1,padding=\"same\")(x1)\n",
        "        x=BatchNormalization()(x)\n",
        "        if NL==\"HS\":\n",
        "            x=h_swish(x)\n",
        "        elif NL==\"RE\":\n",
        "            x=tf.nn.relu6(x)\n",
        "        x=DepthwiseConv2D(kernel_size=(k, k),strides=s,padding=\"same\")(x)\n",
        "        x=BatchNormalization()(x)\n",
        "        if NL==\"HS\":\n",
        "            x=h_swish(x)\n",
        "        elif NL==\"RE\":\n",
        "            x=tf.nn.relu6(x)\n",
        "        if is_se_existing:\n",
        "            x=se_block(x,input_channels=exp_size)\n",
        "        x=Conv2D(filters=out_size,kernel_size=(1, 1),strides=1,padding=\"same\")(x)\n",
        "        x=BatchNormalization()(x)\n",
        "        x=Activation(tf.keras.activations.linear)(x)\n",
        "        if s==1 and in_size==out_size:\n",
        "            x=add([x,x1])\n",
        "        return x\n",
        "    input=Input(input_shape)\n",
        "    x=Conv2D(filters=16,kernel_size=(3,3),strides=2,padding=\"same\")(input)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=BottleNeck(x,in_size=16, exp_size=16, out_size=16, s=2, is_se_existing=True, NL=\"RE\", k=3)\n",
        "    x=BottleNeck(x,in_size=16, exp_size=72, out_size=24, s=2, is_se_existing=False, NL=\"RE\", k=3)\n",
        "    x=BottleNeck(x,in_size=24, exp_size=88, out_size=24, s=1, is_se_existing=False, NL=\"RE\", k=3)\n",
        "    x=BottleNeck(x,in_size=24, exp_size=96, out_size=40, s=2, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=BottleNeck(x,in_size=40, exp_size=240, out_size=40, s=1, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=BottleNeck(x,in_size=40, exp_size=240, out_size=40, s=1, is_se_existing=True, NL=\"HS\", k=5)   \n",
        "    x=BottleNeck(x,in_size=40, exp_size=120, out_size=48, s=1, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=BottleNeck(x,in_size=48, exp_size=144, out_size=48, s=1, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=BottleNeck(x,in_size=48, exp_size=288, out_size=96, s=2, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=BottleNeck(x,in_size=96, exp_size=576, out_size=96, s=1, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=BottleNeck(x,in_size=96, exp_size=576, out_size=96, s=1, is_se_existing=True, NL=\"HS\", k=5)\n",
        "    x=Conv2D(filters=576,kernel_size=(1,1),strides=1,padding=\"same\")(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=AvgPool2D(pool_size=(4, 4),strides=1)(x)\n",
        "    x=Conv2D(filters=1024,kernel_size=(1,1),strides=1,padding=\"same\")(x)\n",
        "    output=Conv2D(filters=n_classes,kernel_size=(1,1),strides=1,padding=\"same\",activation=tf.keras.activations.sigmoid)(x)\n",
        "    \n",
        "    model = Model(input, output)\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "input_shape=112,112,1\n",
        "n_classes=1\n",
        "\n",
        "model = mobile_netv3(input_shape,n_classes)\n",
        "model.summary()\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy','Precision','Recall'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhXyBCtmlYIy"
      },
      "source": [
        "################################################################  \n",
        "opt=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.995, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam')\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy','Precision','Recall'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1,restore_best_weights=True)\n",
        "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"Mobile_Covid.h5\", save_best_only=True)\n",
        "\n",
        "log_csv=CSVLogger(\"/content/drive/MyDrive/CSV_logger/two_class_covid_Mnetv3.csv\",separator=\",\", append=False)\n",
        "\n",
        "\n",
        "callbacks_list = [early_stop, log_csv, checkpoint_cb,checkpoint_cb]\n",
        "\n",
        "history = model.fit(train_it, epochs=15,steps_per_epoch=len(X_train)/2,validation_data=(X_val,y_val),callbacks=callbacks_list)\n",
        "#,callbacks=callbacks_list,len(X_train)/4\n",
        "#callbacks_list = [early_stop, log_csv]\n",
        "\n",
        "#history = model.fit(X_train, y_train, batch_size = 32, verbose = 1, epochs = 20,validation_split=0.1)\n",
        "                         \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K8cDK6zl3wM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEyo3_P5srf3"
      },
      "source": [
        "model=keras.models.load_model(\"/content/Mobile_Covid.h5\")\n",
        "test_loss,test_acc,test_Pre,test_recall=model.evaluate(X_test,y_test)\n",
        "print(test_loss)\n",
        "print(test_acc)\n",
        "test_Pre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfU79Mddt3VI"
      },
      "source": [
        "hist=history\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Classifier Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'],loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Classifier Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'],loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgfyKJDMt6Z_"
      },
      "source": [
        "################# Ideal Theshold Calculation ############################\n",
        "\n",
        "y_prob=model.predict(X_test).ravel()\n",
        "y_test=np.array(y_test).ravel()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def roc_curve(y_test, y_prob, thresholds):\n",
        "\n",
        "    fpr = []\n",
        "    tpr = []\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "\n",
        "        y_pred = np.where(y_prob >= threshold, 1, 0)\n",
        "\n",
        "        fp = np.sum((y_pred == 1) & (y_test== 0))\n",
        "        tp = np.sum((y_pred == 1) & (y_test == 1))\n",
        "\n",
        "        fn = np.sum((y_pred == 0) & (y_test == 1))\n",
        "        tn = np.sum((y_pred == 0) & (y_test == 0))\n",
        "\n",
        "        fpr.append(fp / (fp + tn))\n",
        "        tpr.append(tp / (tp + fn))\n",
        "\n",
        "    return [fpr, tpr]\n",
        "\n",
        "y_prob1 = model.predict(X_test).ravel()\n",
        "thresholds1= list(np.arange(-1, 1, 0.001))\n",
        "[fpr1,tpr1]=roc_curve(y_test,y_prob1, thresholds1)\n",
        "thresholds1=np.array(thresholds1)\n",
        "tpr1=np.array(tpr1)\n",
        "fpr1=np.array(fpr1)\n",
        "import pandas as pd\n",
        "i = np.arange(len(tpr1)) \n",
        "roc1 = pd.DataFrame({'tf' : pd.Series(tpr1-(1-fpr1), index=i), 'thresholds1' : pd.Series(thresholds1, index=i)})\n",
        "ideal_roc_thresh1 = roc1.iloc[(roc1.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\n",
        "print(\"Ideal threshold is: \", ideal_roc_thresh1['thresholds1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-dsxUY0uCnm"
      },
      "source": [
        "############## Confusion Matrix Calculation###################\n",
        "\n",
        "series_list=ideal_roc_thresh1['thresholds1'].tolist()\n",
        "mythreshold=series_list[0]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, plot_roc_curve\n",
        "\n",
        "y_prob=model.predict(X_test)\n",
        "y_pred = (((y_prob)>= mythreshold).astype(int)).ravel()\n",
        "print((type(y_pred)))\n",
        "\n",
        "y_test=np.array(y_test).ravel()\n",
        "y_pred1=y_pred\n",
        "cm=confusion_matrix(y_test, y_pred1)    #################### Confusion Matrix\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtHlZISUfH_P"
      },
      "source": [
        "print(y_test-y_pred1)\n",
        "print(y_pred1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eepbqg0SuNCY"
      },
      "source": [
        "#################Confusion Metrics plot ###################################\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from make_confusion_matrix import make_confusion_matrix\n",
        "from calc_precision_recall import calc_precision_recall\n",
        "TP,TN,FP,FN,precision, recall=calc_precision_recall(y_test, y_pred)\n",
        "\n",
        "f2_score=(5*precision*recall) / ((4*precision) + recall)\n",
        "print(f2_score)\n",
        "\n",
        "cm=confusion_matrix(y_test_label,y_pred)\n",
        "make_confusion_matrix(cm, figsize=(8,6), cbar=False,title=\"Confusion Matrix\",categories=['abnormal heart beats',\"Covid\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdpTsLZuuPE_"
      },
      "source": [
        "############################################### ROC Curve\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(fpr1, tpr1,linewidth=3, color='Red')\n",
        "plt.plot([0, 1], [0, 1], 'y--',linewidth=3)\n",
        "plt.xlabel('False positive rate', fontsize=15, color='Blue')\n",
        "plt.ylabel('True positive rate',fontsize=15,color='Blue')\n",
        "plt.title('ROC curve ',fontsize=18,color='Blue')\n",
        "plt.legend(['Resnet Classifier(AUC=1.0)','Random Classifier(AUC=0.5)'],loc='lower right', fontsize=10)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3M9_zYO0rQN"
      },
      "source": [
        "fpr1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WanApIdluSaH"
      },
      "source": [
        "###### Inference Time #############################\n",
        "Number_of_samples=len(y_test)\n",
        "import time\n",
        "start_time=time.time()\n",
        "y_preds = model.predict(X_test)\n",
        "total_time=time.time()-start_time\n",
        "print(total_time)\n",
        "# Inference Time\n",
        "Inference=total_time/Number_of_samples\n",
        "print(Inference)\n",
        "# Frames Per Second                    \n",
        "FPS=1/Inference\n",
        "print([\"FPS=\",FPS])\n",
        "\n",
        "print(\"Inference Time = \", Inference)\n",
        "print(\"FPS = \", FPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05yaBZGNuXU_"
      },
      "source": [
        "###### Inference Time #############################\n",
        "Number_of_samples=len(y_test)\n",
        "import time\n",
        "start_time=time.time()\n",
        "y_preds = model.predict(X_test)\n",
        "total_time=time.time()-start_time\n",
        "print(total_time)\n",
        "FPS=total_time/Number_of_samples\n",
        "print(FPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjIVJNuBuYNo"
      },
      "source": [
        "y_pred = (model.predict(X_test)>= mythreshold).astype(int)\n",
        "TP,TN,FP,FN,precision, recall = calc_precision_recall(y_test, y_pred)\n",
        "Accuracy=((TP+TN)/(TP+TN+FP+FN))*100\n",
        "Sensitivity=(TP/(TP+FN))*100\n",
        "Specificity=(TN/(TN+FP))*100\n",
        "Precision=(TP/(TP+FP))*100\n",
        "Recall= Sensitivity\n",
        "f2_score=((5*Precision*Recall) / ((4*Precision) + Recall))/100\n",
        "\n",
        "\n",
        "##################### AUC ################\n",
        "\n",
        "y_preds = model.predict(X_test).ravel()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
        "from sklearn.metrics import auc\n",
        "auc_value = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "# assign values to lists.  \n",
        "data = [{'Model':'Model1','Accuracy': Accuracy,'Precision':Precision, 'Sensitivity': Sensitivity, 'Specificity':Specificity,'F2-score':f2_score,'ROC-AUC':auc_value}]  \n",
        "  \n",
        "# Creates DataFrame.  \n",
        "df = pd.DataFrame(data)  \n",
        "df.index+=1\n",
        "# Print the data  \n",
        "print(df)\n",
        "print(\"Ideal threshold =\", mythreshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXqszL0Qugqo"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.utils.plot_model(model, 'multi_input_and_output_model.png', \n",
        "show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVNWNWHeLLl_"
      },
      "source": [
        "\"\"\"\n",
        "# Reference\n",
        "- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks]\n",
        "   (https://arxiv.org/abs/1905.11946)\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_top(x_input):\n",
        "    \"\"\"Block top operations\n",
        "    This functions apply Batch Normalization and Leaky ReLU activation to the input.\n",
        "    # Arguments:\n",
        "        x_input: Tensor, input to apply BN and activation  to.\n",
        "    # Returns:\n",
        "        Output tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    x = tf.keras.layers.BatchNormalization()(x_input)\n",
        "    x = tf.keras.layers.LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "def get_block(x_input, input_channels, output_channels):\n",
        "    \"\"\"MBConv block\n",
        "    This function defines a mobile Inverted Residual Bottleneck block with BN and Leaky ReLU\n",
        "    # Arguments\n",
        "        x_input: Tensor, input tensor of conv layer.\n",
        "        input_channels: Integer, the dimentionality of the input space.\n",
        "        output_channels: Integer, the dimensionality of the output space.\n",
        "            \n",
        "    # Returns\n",
        "        Output tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(input_channels, kernel_size=(1, 1), padding='same', use_bias=False)(x_input)\n",
        "    x = get_top(x)\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size=(1, 3), padding='same', use_bias=False)(x)\n",
        "    x = get_top(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), strides=(2, 1))(x)\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 1), padding='same', use_bias=False)(x)\n",
        "    x = get_top(x)\n",
        "    x = tf.keras.layers.Conv2D(output_channels, kernel_size=(2, 1), strides=(1, 2), padding='same', use_bias=False)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def EffNet(input_shape, num_classes, plot_model=False):\n",
        "    \"\"\"EffNet\n",
        "    This function defines a EfficientNet architecture.\n",
        "    # Arguments\n",
        "        input_shape: An integer or tuple/list of 3 integers, shape\n",
        "            of input tensor.\n",
        "        num_classes: Integer, number of classes.\n",
        "        plot_model: Boolean, whether to plot model architecture or not\n",
        "    # Returns\n",
        "        EfficientNet model.\n",
        "    \"\"\"\n",
        "    x_input = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = get_block(x_input, 32, 64)\n",
        "    x = get_block(x, 64, 128)\n",
        "    x = get_block(x, 128, 256)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs=x_input, outputs=x)\n",
        "    \n",
        "    if plot_model:\n",
        "        tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "    return model\n",
        "model=EffNet((224,224,1),1,True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MSp-TT6ThM"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lci8eISp6dlT"
      },
      "source": [
        "tf.keras.utils.plot_model(model, 'multi_input_and_output_model.png', \n",
        "show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5csMCYx6_CT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsQ9uD1tvp8K"
      },
      "source": [
        "############################################### ROC Curve\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(fpr1, tpr1,linewidth=3, marker='.', color='Red')\n",
        "plt.plot([0, 1], [0, 1], 'y--',linewidth=3)\n",
        "plt.xlabel('False positive rate', fontsize=15, color='Blue')\n",
        "plt.ylabel('True positive rate',fontsize=15,color='Blue')\n",
        "plt.title('ROC curve ',fontsize=18,color='Blue')\n",
        "plt.legend(['CNN Classifier(AUC=1.0)','Random Classifier(AUC=0.5)'],loc='lower right', fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dedFNMjzvxP3"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}